{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7f7ca1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e3f541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, checkpoint_filename, checkpoint_index=None):\n",
    "    torch.save(state, checkpoint_filename)\n",
    "    if checkpoint_index is not None:\n",
    "        torch.save(state, checkpoint_filename.replace(\".pth.tar\", str(checkpoint_index) + \".pth.tar\"))\n",
    "    print(\"[INFO] Checkpoint saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73d2cf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint, model, optimizer_class, optimizer_mask):\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer_class.load_state_dict(checkpoint[\"optimizer_class\"])\n",
    "    optimizer_mask.load_state_dict(checkpoint[\"optimizer_mask\"])\n",
    "    print(\"[INFO] Checkpoint loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8075ddaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_epoch(title, epoch, classification_acc, f1_score, classification_dice, segmentation_acc, segmentation_dice, train_log_filename): \n",
    "    f = open(train_log_filename, 'a+') \n",
    "    f.write(f\"\\n[{title}] Epoch {epoch}:\\\n",
    "    \\n[Classification] Accuracy: {classification_acc:.2f}, Dice Score: {classification_dice:.2f}, F1 Score: {f1_score:.2f}\\\n",
    "    \\n[Segmentation]   Accuracy: {segmentation_acc:.2f}, Dice Score {segmentation_dice:.2f}\") \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4cd6c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_train(epoch, classification_loss, segmentation_loss, classification_acc, segmentation_acc, classification_dice, segmentation_dice, train_log_filename):\n",
    "    f = open(train_log_filename, 'a+') \n",
    "    f.write(f\"\\n[TRAIN] Epoch {epoch}:\\\n",
    "    \\n[Classification] Loss: {classification_loss:.2f}, Accuracy: {classification_acc:.2f}, Dice Score: {classification_dice:.2f}\\\n",
    "    \\n[Segmentation]   Loss: {segmentation_loss:.2f}, Accuracy: {segmentation_acc:.2f}, Dice Score: {segmentation_dice:.2f}\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ad0b76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_incorporate (loader, model, device):\n",
    "    tp = tn = fp = fn = 0\n",
    "    num_correct = num_pixels = 0\n",
    "    dice_score = count_dice = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y1, y2 in tqdm(loader):\n",
    "            x = x.to(device)\n",
    "            y1 = y1.long().to(device)\n",
    "            y2 = y2.float().unsqueeze(1).to(device)\n",
    "      \n",
    "            out1, out2 = model(x)\n",
    "\n",
    "            pred1 = out1.argmax(dim=1, keepdim=True)\n",
    "            truth1 = y1.view_as(pred1)\n",
    "            tp += (pred1 * truth1).sum()\n",
    "            tn += ((1 - pred1).abs() * (1 - truth1).abs()).sum()\n",
    "            fp += (pred1 * (1 - truth1).abs()).sum()\n",
    "            fn += ((1 - pred1).abs() * truth1).sum()\n",
    "\n",
    "            pred2 = torch.sigmoid(out2)\n",
    "            pred2 = (pred2 > 0.5).float()\n",
    "            num_correct += (pred2[truth1==1] == y2[truth1==1]).sum()\n",
    "            num_pixels += torch.numel(pred2[truth1==1])\n",
    "\n",
    "            if torch.sum(truth1==1) > 0:\n",
    "                dice_score += (2 * (pred2[truth1==1] * y2[truth1==1]).sum()) / ((pred2[truth1==1] + y2[truth1==1]).sum())\n",
    "                count_dice += 1\n",
    "\n",
    "    percision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "\n",
    "    f1 = 2 * percision * recall / (percision + recall) \n",
    "    accuracy_class = (tp + tn) / (tp + tn + fp + fn) * 100\n",
    "    dice_class = tp / (fp + fn + tp) * 100\n",
    "\n",
    "    if count_dice > 0:\n",
    "        accuracy_mask = num_correct/num_pixels*100\n",
    "        dice_mask = dice_score/count_dice*100\n",
    "    else:\n",
    "        accuracy_mask = 0\n",
    "        dice_mask = 0\n",
    "\n",
    "    print(\"\\n[EVAL]\")\n",
    "    print(f\"[Classification]: Dice: {dice_class:2f}, Acc: {accuracy_class:2f}, F1: {f1:2f},\")\n",
    "    print(f\"[Segmentation]:   Dice: {dice_mask:2f},  Acc: {accuracy_mask:2f}\")\n",
    "    print(f\"[Confusion]:      TP: {tp.item()}, TN: {tn.item()}, FP: {fp.item()}, FN: {fn.item()}\")\n",
    "\n",
    "    return f1, dice_class, accuracy_class, dice_mask, accuracy_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4393b8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_single (loader, model, device):\n",
    "    tp = tn = fp = fn = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y1, y2 in tqdm(loader):\n",
    "            x = x.to(device)\n",
    "            y1 = y1.long().to(device)\n",
    "      \n",
    "            out1 = model(x)\n",
    "\n",
    "            pred1 = out1.argmax(dim=1, keepdim=True)\n",
    "            truth1 = y1.view_as(pred1)\n",
    "            tp += (pred1 * truth1).sum()\n",
    "            tn += ((1 - pred1).abs() * (1 - truth1).abs()).sum()\n",
    "            fp += (pred1 * (1 - truth1).abs()).sum()\n",
    "            fn += ((1 - pred1).abs() * truth1).sum()\n",
    "\n",
    "    percision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "\n",
    "    f1 = 2 * percision * recall / (percision + recall) \n",
    "    accuracy_class = (tp + tn) / (tp + tn + fp + fn) * 100\n",
    "    dice_class = tp / (fp + fn + tp) * 100\n",
    "\n",
    "    print(\"\\n[EVAL]\")\n",
    "    print(f\"[Classification]: Dice: {dice_class:2f}, Acc: {accuracy_class:2f}, F1: {f1:2f},\")\n",
    "    print(f\"[Confusion]:      TP: {tp.item()}, TN: {tn.item()}, FP: {fp.item()}, FN: {fn.item()}\")\n",
    "\n",
    "    dice_mask = accuracy_mask = 0.0\n",
    "\n",
    "    return f1, dice_class, accuracy_class, dice_mask, accuracy_mask"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
