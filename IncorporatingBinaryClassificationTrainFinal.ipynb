{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af950548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install import-ipynb\n",
    "# !pip install albumentations==0.4.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6ffe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd D:\\YSC2023\\Implementation\\Train_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75512b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import import_ipynb\n",
    "import torch\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "from Utils_EvalTest import evaluate_model_incorporate, evaluate_model_single, save_checkpoint, load_checkpoint, log_epoch, log_train\n",
    "from Utils_Dataset import get_png_data_loader, get_hu_data_loader\n",
    "from Utils_Train import DiceBCEWithLogisticLoss, CustomAccuracyLoss, FocalTverskyLoss, train_single, train_incorporate\n",
    "from CRNet import CRNet\n",
    "from CrAsppReUNet import CRASPPReUNet\n",
    "from CustomFinalCrAsppReUNet import CustomFinalCRASPPReUNet\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3951e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "start_epoch = 0         #if resume training, change to the last training index\n",
    "\n",
    "is_load_to_ram = False  #load training data to RAM\n",
    "is_continue = False     #resume trainning\n",
    "\n",
    "is_HU = True           #HU or 255 (DICOM or PNG)\n",
    "HU_range = 900.0        #from -1000 to -100\n",
    "is_concat_lung = True   #keep as True (False for NO concatenation of lung masks)\n",
    "is_full_size = False     #512 or 256\n",
    "is_cap = False         #classification with CAP or healthy cases\n",
    "\n",
    "# uncomment to select model \n",
    "# model_name = \"crnet\"                  #CRNet\n",
    "# model_name = \"crasppreunet\"           #CR-IM\n",
    "model_name = \"crasppreunet_custom\"    #CR-IM-SCRC\n",
    "# model_name = \"densenet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a5ce76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving_directory = r'D:\\YSC2023\\Implementation\\Final_Output\\CRNet_HU_256'                      \n",
    "# saving_directory = r'D:\\YSC2023\\Implementation\\Final_Output\\CRNet_PNG_256'    \n",
    "# saving_directory = r'D:\\YSC2023\\Implementation\\Final_Output\\Temp'  \n",
    "saving_directory = r'D:/YSC2023/Implementation/Final_Output_DatasetSplit/Lung_mask/XNet_HU_256/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7a0d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_crnet():\n",
    "    model = CRNet(img_dimwh=height_crop, in_channels=in_channels)\n",
    "    return model.cuda(), \"single\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67be99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_crasppreunet():\n",
    "    model = CRASPPReUNet(img_dimwh=height_crop, in_channels=in_channels)\n",
    "    return model.cuda(), \"incorporate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666b36d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_crasppreunet_custom():\n",
    "    model = CustomFinalCRASPPReUNet(img_dimwh=height_crop, in_channels=in_channels)\n",
    "    return model.cuda(), \"incorporate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edfd9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(module):\n",
    "    if type(module) == nn.Linear or\\\n",
    "        type(module) == nn.Conv2d or\\\n",
    "        type(module) == nn.ConvTranspose2d:\n",
    "        torch.nn.init.kaiming_normal_(module.weight)\n",
    "    elif type(module) == nn.BatchNorm2d:\n",
    "        nn.init.ones_(module.weight)\n",
    "        nn.init.zeros_(module.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd3b64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = saving_directory + \"/checkpoint.pth.tar\"\n",
    "train_log_filename = saving_directory + \"/train_log\"\n",
    "\n",
    "if not is_HU:\n",
    "    covid_dir = r'D:\\YSC2023\\Implementation\\Dataset_PNG\\COVID'\n",
    "    nonCovid_dir = r'D:\\YSC2023\\Implementation\\Dataset_PNG\\NONCOVID'\n",
    "else:\n",
    "    covid_dir = r'D:\\YSC2023\\Implementation\\Dataset\\COVID'\n",
    "    nonCovid_dir = r'D:\\YSC2023\\Implementation\\Dataset\\NONCOVID'\n",
    "\n",
    "if not is_full_size:\n",
    "    height = width = 256\n",
    "    height_crop = width_crop= 224\n",
    "    blur_kernel = 5\n",
    "else:\n",
    "    height = width = 512\n",
    "    height_crop = width_crop= 448\n",
    "    blur_kernel = 7\n",
    "\n",
    "rotation_limit = 15\n",
    "mean = [0.0, 0.0, 0.0]\n",
    "std = [1.0, 1.0, 1.0]\n",
    "random_crop_scale = 0.8\n",
    "max_pixel_value = 255.0\n",
    "contrast_factor = brightness_factor = 0.2\n",
    "\n",
    "batch_size = 16\n",
    "# batch_size = 64\n",
    "learning_rate_class = 1e-4\n",
    "learning_rate_mask = 1e-5\n",
    "reduction = 'mean'\n",
    "# reduction = 'sum'\n",
    "scheduler_period_class = 10\n",
    "scheduler_period_mask = 10\n",
    "if is_concat_lung:\n",
    "    in_channels = 4\n",
    "else:\n",
    "    in_channels = 3\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"[INFO] Using \" + device + \" for training ...\")\n",
    "\n",
    "if not is_HU:\n",
    "    if not is_cap:\n",
    "        train_list_COVID = r'D:\\YSC2023\\Implementation\\Dataset_PNG\\covid_train.txt'\n",
    "        train_list_NonCOVID = r'D:\\YSC2023\\Implementation\\Dataset_PNG\\normal_train.txt'\n",
    "\n",
    "        val_list_COVID = r'D:\\YSC2023\\Implementation\\Dataset_PNG\\covid_validation.txt'\n",
    "        val_list_NonCOVID = r'D:\\YSC2023\\Implementation\\Dataset_PNG\\normal_validation.txt'\n",
    "\n",
    "        test_list_COVID = r'D:\\YSC2023\\Implementation\\Dataset_PNG\\covid_test.txt'\n",
    "        test_list_NonCOVID = r'D:\\YSC2023\\Implementation\\Dataset_PNG\\normal_test.txt'\n",
    "    else:\n",
    "        print(\"[INFO] CAP\")\n",
    "        train_list_COVID = r'D:\\YSC2023\\Implementation\\Dataset_PNG\\covid_train.txt'\n",
    "        train_list_NonCOVID = 'D:\\YSC2023\\Implementation\\Dataset_PNG\\cap_train.txt'\n",
    "    \n",
    "        val_list_COVID = r'D:\\YSC2023\\Implementation\\Dataset_PNG\\covid_validation.txt'\n",
    "        val_list_NonCOVID = \"D:\\YSC2023\\Implementation\\Dataset_PNG\\cap_validation.txt\"\n",
    "\n",
    "        test_list_COVID = r'D:\\YSC2023\\Implementation\\Dataset_PNG\\covid_test.txt'\n",
    "        test_list_NonCOVID = \"D:\\YSC2023\\Implementation\\Dataset_PNG\\cap_test.txt\"\n",
    "else:\n",
    "    if not is_cap:\n",
    "        train_list_COVID = r'D:\\YSC2023\\Implementation\\Dataset\\covid_train.txt'\n",
    "        train_list_NonCOVID = r'D:\\YSC2023\\Implementation\\Dataset\\normal_train.txt'\n",
    "\n",
    "        val_list_COVID = r'D:\\YSC2023\\Implementation\\Dataset\\covid_validation.txt'\n",
    "        val_list_NonCOVID = r'D:\\YSC2023\\Implementation\\Dataset\\normal_validation.txt'\n",
    "\n",
    "        test_list_COVID = r'D:\\YSC2023\\Implementation\\Dataset\\covid_test.txt'\n",
    "        test_list_NonCOVID = r'D:\\YSC2023\\Implementation\\Dataset\\normal_test.txt'\n",
    "    else:\n",
    "        print(\"[INFO] CAP\")   \n",
    "        train_list_COVID = r'D:\\YSC2023\\Implementation\\Dataset\\covid_train.txt'\n",
    "        train_list_NonCOVID = 'D:\\YSC2023\\Implementation\\Dataset\\cap_train.txt'\n",
    "\n",
    "        val_list_COVID = r'D:\\YSC2023\\Implementation\\Dataset\\covid_validation.txt'\n",
    "        val_list_NonCOVID = \"D:\\YSC2023\\Implementation\\Dataset\\cap_validation.txt\"\n",
    "\n",
    "        test_list_COVID = r'D:\\YSC2023\\Implementation\\Dataset\\covid_test.txt'\n",
    "        test_list_NonCOVID = \"D:\\YSC2023\\Implementation\\Dataset\\cap_test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b373096",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_HU:\n",
    "    train_transformer = A.Compose([\n",
    "        A.Resize(height=height, width=width, interpolation=cv2.INTER_AREA),\n",
    "        A.RandomResizedCrop(height=height_crop, width=width_crop, scale=(random_crop_scale, 1.0), interpolation=cv2.INTER_AREA),\n",
    "        A.HorizontalFlip(),\n",
    "        A.Rotate(limit=rotation_limit),\n",
    "        A.GaussNoise(),\n",
    "        A.GaussianBlur(blur_limit=blur_kernel),\n",
    "        A.RandomContrast(limit=contrast_factor),\n",
    "        A.RandomBrightness(limit=brightness_factor),\n",
    "        A.Normalize(\n",
    "            mean=mean,\n",
    "            std=std,\n",
    "            max_pixel_value=max_pixel_value,\n",
    "        ),\n",
    "        ToTensorV2()\n",
    "        ],\n",
    "        additional_targets={'lung_mask': 'mask', 'lesion_mask': 'mask'},\n",
    "        )\n",
    "  \n",
    "    val_transformer = A.Compose([\n",
    "      A.Resize(height=height_crop, width=width_crop),\n",
    "      A.CenterCrop(height=height_crop, width=width_crop),\n",
    "      A.Normalize(\n",
    "          mean=mean,\n",
    "          std=std,\n",
    "          max_pixel_value=max_pixel_value,\n",
    "      ),\n",
    "      ToTensorV2()\n",
    "      ],\n",
    "      additional_targets={'lung_mask': 'mask', 'lesion_mask': 'mask'},\n",
    "      )\n",
    "else:\n",
    "    train_transformer = A.Compose([\n",
    "        A.ToFloat(max_value=HU_range),\n",
    "        A.Resize(height=height, width=width, interpolation=cv2.INTER_AREA),\n",
    "        A.RandomResizedCrop(height=height_crop, width=width_crop, scale=(random_crop_scale, 1.0), interpolation=cv2.INTER_AREA),\n",
    "        A.HorizontalFlip(),\n",
    "        A.Rotate(limit=rotation_limit),\n",
    "        A.GaussianBlur(blur_limit=blur_kernel),\n",
    "        A.RandomContrast(limit=contrast_factor),\n",
    "        A.RandomBrightness(limit=brightness_factor),\n",
    "        ToTensorV2()\n",
    "        ],\n",
    "        additional_targets={'lung_mask': 'mask', 'lesion_mask': 'mask'},\n",
    "        )\n",
    "\n",
    "    val_transformer = A.Compose([\n",
    "        A.ToFloat(max_value=HU_range),\n",
    "        A.Resize(height=height_crop, width=width_crop),\n",
    "        A.CenterCrop(height=height_crop, width=width_crop),\n",
    "        ToTensorV2()\n",
    "        ],\n",
    "        additional_targets={'lung_mask': 'mask', 'lesion_mask': 'mask'},\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f607abc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == \"densenet\":\n",
    "    model, mode = load_densenet(pretrained=is_pretrained)\n",
    "if model_name == \"crnet\":\n",
    "    model, mode = load_crnet()\n",
    "if model_name == \"crasppreunet\":\n",
    "    model, mode = load_crasppreunet()\n",
    "if model_name == \"crasppreunet_custom\":\n",
    "    model, mode = load_crasppreunet_custom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940e9ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45b5060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn_class = nn.BCEWithLogitsLoss(reduction=reduction).cuda()\n",
    "loss_fn_class = DiceBCEWithLogisticLoss(reduction=reduction).cuda()\n",
    "# loss_fn_mask = nn.BCEWithLogitsLoss(reduction=reduction).cuda()\n",
    "# loss_fn_mask = DiceBCEWithLogisticLoss(reduction=reduction).cuda()\n",
    "# loss_fn_mask = CustomAccuracyLoss().cuda()\n",
    "loss_fn_mask = FocalTverskyLoss().cuda()\n",
    "optimizer_class = optim.Adam(model.parameters(), lr=learning_rate_class)\n",
    "optimizer_mask = optim.Adam(model.parameters(), lr=learning_rate_mask)\n",
    "scheduler_class = optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer_class, T_max=scheduler_period_class)\n",
    "scheduler_mask = optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer_mask, T_max=scheduler_period_mask)\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a947e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_HU:\n",
    "    train_loader, val_loader, test_loader = get_png_data_loader(\n",
    "      covid_dir=covid_dir,\n",
    "      nonCovid_dir=nonCovid_dir,\n",
    "      train_list_COVID=train_list_COVID,\n",
    "      train_list_NonCOVID=train_list_NonCOVID,\n",
    "      train_transformer=train_transformer,\n",
    "      val_list_COVID=val_list_COVID,\n",
    "      val_list_NonCOVID=val_list_NonCOVID,\n",
    "      val_transformer=val_transformer,\n",
    "      test_list_COVID=test_list_COVID,\n",
    "      test_list_NonCOVID=test_list_NonCOVID,\n",
    "      batch_size=batch_size,\n",
    "      is_load_to_ram=is_load_to_ram,\n",
    "      is_concat_lung=is_concat_lung,\n",
    "      is_cap=is_cap\n",
    "    )\n",
    "else:\n",
    "    train_loader, val_loader, test_loader = get_hu_data_loader(\n",
    "      covid_dir=covid_dir,\n",
    "      nonCovid_dir=nonCovid_dir,\n",
    "      train_list_COVID=train_list_COVID,\n",
    "      train_list_NonCOVID=train_list_NonCOVID,\n",
    "      train_transformer=train_transformer,\n",
    "      val_list_COVID=val_list_COVID,\n",
    "      val_list_NonCOVID=val_list_NonCOVID,\n",
    "      val_transformer=val_transformer,\n",
    "      test_list_COVID=test_list_COVID,\n",
    "      test_list_NonCOVID=test_list_NonCOVID,\n",
    "      batch_size=batch_size,\n",
    "      is_load_to_ram=is_load_to_ram,\n",
    "      is_concat_lung=is_concat_lung,\n",
    "      is_cap=is_cap\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5f403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "if is_continue:\n",
    "    load_checkpoint(torch.load(checkpoint_path.replace(\".pth.tar\", str(start_epoch - 1) + \".pth.tar\")), model, optimizer_class, optimizer_class)\n",
    "    start = start_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274cad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c33a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "for epoch in range(start, epochs):\n",
    "    print(\"\\nEpoch:\", epoch)\n",
    "    if mode == \"incorporate\":\n",
    "        loss_class, loss_mask, accuracy_class, accuracy_mask, dice_class, dice_mask = train_incorporate(\n",
    "            loader=train_loader, \n",
    "            model=model,\n",
    "            optimizer_class=optimizer_class,\n",
    "            optimizer_mask=optimizer_mask, \n",
    "            loss_fn_class=loss_fn_class,\n",
    "            loss_fn_mask=loss_fn_mask, \n",
    "            scaler=scaler, \n",
    "            device=device)\n",
    "    if mode == \"single\":\n",
    "        loss_class, loss_mask, accuracy_class, accuracy_mask, dice_class, dice_mask = train_single(\n",
    "            loader=train_loader, \n",
    "            model=model,\n",
    "            optimizer=optimizer_class,\n",
    "            loss_fn=loss_fn_class,\n",
    "            scaler=scaler, \n",
    "            device=device)\n",
    "    log_train(epoch, loss_class, loss_mask, accuracy_class, accuracy_mask, dice_class, dice_mask, train_log_filename)\n",
    "  \n",
    "    if mode == \"incorporate\":\n",
    "        f1, dice_class, accuracy_class, dice_mask, accuracy_mask = evaluate_model_incorporate(loader=val_loader, model=model, device=device)\n",
    "    if mode == \"single\":\n",
    "        f1, dice_class, accuracy_class, dice_mask, accuracy_mask = evaluate_model_single(loader=val_loader, model=model, device=device)\n",
    "\n",
    "    log_epoch(\"EVAL\", epoch, accuracy_class, f1, dice_class, accuracy_mask, dice_mask, train_log_filename)\n",
    "    checkpoint = {\n",
    "          \"epoch\": epoch,\n",
    "          \"state_dict\": model.state_dict(),\n",
    "          \"optimizer_class\": optimizer_class.state_dict(),\n",
    "          \"optimizer_mask\": optimizer_mask.state_dict()\n",
    "    }\n",
    "    save_checkpoint(state=checkpoint, checkpoint_filename=checkpoint_path, checkpoint_index=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890ae052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "best_socre = 0\n",
    "best_model_index = 0\n",
    "f = open(train_log_filename, 'a+')\n",
    "f.write(\"\\n ###Test###\")\n",
    "f.close()\n",
    "\n",
    "# for i in range(epochs):\n",
    "for i in range(start, epochs):\n",
    "    print(\"\\nEpoch:\", i)\n",
    "    load_checkpoint(torch.load(checkpoint_path.replace(\".pth.tar\", str(i) + \".pth.tar\")), model, optimizer_class,optimizer_mask)\n",
    "    if mode == \"incorporate\":\n",
    "        f1, dice_class, accuracy_class, dice_mask, accuracy_mask = evaluate_model_incorporate(loader=test_loader, model=model, device=device)\n",
    "    if mode == \"single\":\n",
    "        f1, dice_class, accuracy_class, dice_mask, accuracy_mask = evaluate_model_single(loader=test_loader, model=model, device=device)\n",
    "    log_epoch(\"TEST\", i, accuracy_class, f1, dice_class, accuracy_mask, dice_mask, train_log_filename)\n",
    "\n",
    "    score = f1 + dice_class + dice_mask\n",
    "    if score > best_socre:\n",
    "        print(\"Best is: \", i)\n",
    "        best_socre = score\n",
    "        best_model_index = i\n",
    "        checkpoint = {\n",
    "          \"epoch\": i,\n",
    "          \"state_dict\": model.state_dict(),\n",
    "          \"optimizer_class\": optimizer_class.state_dict(),\n",
    "          \"optimizer_mask\": optimizer_mask.state_dict()\n",
    "        }\n",
    "        save_checkpoint(state=checkpoint,checkpoint_filename=checkpoint_path)\n",
    "\n",
    "f = open(train_log_filename, 'a+')\n",
    "f.write(f\"\\n Best model is model with index: {best_model_index}\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e84605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = saving_directory + \"/checkpoint.pth.tar\"\n",
    "load_checkpoint(torch.load(checkpoint_path), model, optimizer_class,optimizer_mask)\n",
    "\n",
    "if mode == \"incorporate\":\n",
    "    f1, dice_class, accuracy_class, dice_mask, accuracy_mask = evaluate_model_incorporate(loader=test_loader, model=model, device=device)\n",
    "\n",
    "if mode == \"single\":\n",
    "    f1, dice_class, accuracy_class, dice_mask, accuracy_mask = evaluate_model_single(loader=test_loader, model=model, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77f77fd",
   "metadata": {},
   "source": [
    "# Predict Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8166472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = torch.load(r'D:/YSC2023/Implementation/Final_Output_DatasetSplit/Lung_mask/XNet_HU_256/checkpoint.pth.tar')\n",
    "# model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f85f54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "# Lấy batch đầu tiên của DataLoader\n",
    "batch = next(iter(test_loader))\n",
    "\n",
    "# Lấy các ảnh từ batch và chuyển sang numpy array\n",
    "images = batch[0].numpy()\n",
    "\n",
    "# Hiển thị các ảnh\n",
    "grid_img = torchvision.utils.make_grid(batch[0], nrow=4)\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(grid_img.permute(1, 2, 0))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8212b8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = batch[0][0]\n",
    "plt.imshow(image.permute(1, 2, 0)) # need to permute the dimensions to (height, width, channels)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc6767e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_index, (image, label, mask) in enumerate(test_loader):\n",
    "        if batch_index == 5:\n",
    "            break\n",
    "\n",
    "        data = image.to(device)\n",
    "\n",
    "        label = label.long().to(device)\n",
    "        filter = label.reshape(-1, 1)\n",
    "        target_mask = mask.float().unsqueeze(1).to(device)\n",
    "\n",
    "        output_class, output_mask = model(data)\n",
    "        target_class = torch.zeros_like(output_class, device=device)\n",
    "        target_class[np.arange(data.size(0)), label] = 1\n",
    "\n",
    "        prediction_mask = torch.sigmoid(output_mask)\n",
    "        prediction_mask = (prediction_mask > 0.5).float()\n",
    "\n",
    "        #### display images\n",
    "        image = np.transpose(image.cpu().numpy(), (0, 2, 3, 1))\n",
    "        label =  target_mask[0].cpu().numpy()\n",
    "        prediction_mask = prediction_mask[0].cpu().numpy().squeeze()\n",
    "\n",
    "\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "        axs[0].imshow(image[0])\n",
    "        axs[0].axis(\"off\")\n",
    "        axs[0].set_title(\"Image\")\n",
    "\n",
    "        axs[1].imshow(label[0], cmap=\"gray\")\n",
    "        axs[1].axis(\"off\")\n",
    "        axs[1].set_title(\"Label\")\n",
    "\n",
    "        axs[2].imshow(prediction_mask, cmap=\"gray\")\n",
    "        axs[2].axis(\"off\")\n",
    "        axs[2].set_title(\"Predicted Mask\")\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddab364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_index, (image, label, mask) in enumerate(test_loader):\n",
    "        if batch_index == 5:\n",
    "            break\n",
    "\n",
    "        data = image.to(device)\n",
    "\n",
    "        label = label.long().to(device)\n",
    "        filter = label.reshape(-1, 1)\n",
    "        target_mask = mask.float().unsqueeze(1).to(device)\n",
    "\n",
    "        output_class, output_mask = model(data)\n",
    "        target_class = torch.zeros_like(output_class, device=device)\n",
    "        target_class[np.arange(data.size(0)), label] = 1\n",
    "\n",
    "        prediction_mask = torch.sigmoid(output_mask)\n",
    "        prediction_mask = (prediction_mask > 0.5).float()\n",
    "\n",
    "        #### display images\n",
    "        image = np.transpose(image.cpu().numpy(), (0, 2, 3, 1))\n",
    "        label =  target_mask[0].cpu().numpy()\n",
    "        prediction_mask = prediction_mask[0].cpu().numpy().squeeze()\n",
    "        \n",
    "        # Chuyển đổi không gian màu từ RGBA sang RGB\n",
    "        lung_image = cv2.cvtColor(image[0], cv2.COLOR_RGBA2RGB)\n",
    "        label_image = label[0]\n",
    "        predict_image = prediction_mask\n",
    "\n",
    "        # Nếu ảnh label và predict giống nhau thì vẽ màu xanh lên ảnh lung\n",
    "        mask = np.logical_and(label_image, predict_image)\n",
    "        lung_image[mask] = (0, 255, 0)\n",
    "\n",
    "        # Nếu ảnh label không có mà ảnh predict có thì vẽ màu đỏ lên ảnh lung\n",
    "        mask = np.logical_and(np.logical_not(label_image), predict_image)\n",
    "        lung_image[mask] = (255, 0, 0)\n",
    "\n",
    "        # Nếu ảnh label có mà ảnh predict không có thì vẽ màu vàng lên ảnh lung\n",
    "        mask = np.logical_and(label_image, np.logical_not(predict_image))\n",
    "        lung_image[mask] = (255, 255, 0)\n",
    "        \n",
    "        fig, axs = plt.subplots(1, 2, figsize=(12, 8))\n",
    "        axs[0].imshow(image[0])\n",
    "        axs[0].axis(\"off\")\n",
    "        axs[0].set_title(\"Image\")\n",
    "\n",
    "        axs[1].imshow(lung_image)\n",
    "        axs[1].axis(\"off\")\n",
    "        axs[1].set_title(\"Predicted\")\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d579d0b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
